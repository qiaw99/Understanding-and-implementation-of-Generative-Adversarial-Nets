

@misc{goodfellow2014generative, title={Generative Adversarial Networks}, author={Ian J. Goodfellow and Jean Pouget-Abadie and Mehdi Mirza and Bing Xu and David Warde-Farley and Sherjil Ozair and Aaron Courville and Yoshua Bengio}, year={2014}, eprint={1406.2661}, archivePrefix={arXiv}, primaryClass={stat.ML} }

@Inbook{Bacharach1991,
    author="Bacharach, Michael",
    editor="Eatwell, John
    and Milgate, Murray
    and Newman, Peter",
    title="Zero-sum Games",
    bookTitle="The World of Economics",
    year="1991",
    publisher="Palgrave Macmillan UK",
    address="London",
    pages="727--731",
    isbn="978-1-349-21315-3",
    doi="10.1007/978-1-349-21315-3_100",
    url="https://doi.org/10.1007/978-1-349-21315-3_100"
}


@article{MYUNG200390,
title = {Tutorial on maximum likelihood estimation},
journal = {Journal of Mathematical Psychology},
volume = {47},
number = {1},
pages = {90-100},
year = {2003},
issn = {0022-2496},
doi = {https://doi.org/10.1016/S0022-2496(02)00028-7},
url = {https://www.sciencedirect.com/science/article/pii/S0022249602000287},
author = {In Jae Myung},
abstract = {In this paper, I provide a tutorial exposition on maximum likelihood estimation (MLE). The intended audience of this tutorial are researchers who practice mathematical modeling of cognition but are unfamiliar with the estimation method. Unlike least-squares estimation which is primarily a descriptive tool, MLE is a preferred method of parameter estimation in statistics and is an indispensable tool for many statistical modeling techniques, in particular in non-linear modeling with non-normal data. The purpose of this paper is to provide a good conceptual explanation of the method with illustrative examples so the reader can have a grasp of some of the basic principles.}
}

@article{chapelle2009semi,
  title={Semi-supervised learning (chapelle, o. et al., eds.; 2006)[book reviews]},
  author={Chapelle, Olivier and Scholkopf, Bernhard and Zien, Alexander},
  journal={IEEE Transactions on Neural Networks},
  volume={20},
  number={3},
  pages={542--542},
  year={2009},
  publisher={IEEE}
}
%--------------------------------------------
@incollection{hecht1992theory,
  title={Theory of the backpropagation neural network},
  author={Hecht-Nielsen, Robert},
  booktitle={Neural networks for perception},
  pages={65--93},
  year={1992},
  publisher={Elsevier}
}

@incollection{ketkar2017stochastic,
  title={Stochastic gradient descent},
  author={Ketkar, Nikhil},
  booktitle={Deep learning with Python},
  pages={113--132},
  year={2017},
  publisher={Springer}
}

@misc{shlens2014notes,
      title={Notes on Kullback-Leibler Divergence and Likelihood}, 
      author={Jonathon Shlens},
      year={2014},
      eprint={1404.2000},
      archivePrefix={arXiv},
      primaryClass={cs.IT}
}

